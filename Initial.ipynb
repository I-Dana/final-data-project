{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkePNIGYW1ZvdFO05FtF6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/I-Dana/final-data-project/blob/main/Initial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zax9eef3MF0",
        "outputId": "fd79194e-1970-42c2-c134-9c745029761b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The CSV file for London has been saved into data_analytics\\openweather/London_2023_08_21.csv.\n",
            "The CSV file for New York has been saved into data_analytics\\openweather/New York_2023_08_21.csv.\n",
            "The CSV file for Cordoba has been saved into data_analytics\\openweather/Cordoba_2023_08_21.csv.\n",
            "The CSV file for Taipei has been saved into data_analytics\\openweather/Taipei_2023_08_21.csv.\n",
            "The CSV file for Buenos_Aires has been saved into data_analytics\\openweather/Buenos_Aires_2023_08_21.csv.\n",
            "The CSV file for Mexico_DF has been saved into data_analytics\\openweather/Mexico_DF_2023_08_21.csv.\n",
            "The CSV file for Dublin has been saved into data_analytics\\openweather/Dublin_2023_08_21.csv.\n",
            "The CSV file for Tilfis has been saved into data_analytics\\openweather/Tilfis_2023_08_21.csv.\n",
            "The CSV file for Bogota has been saved into data_analytics\\openweather/Bogota_2023_08_21.csv.\n",
            "The CSV file for Tokio has been saved into data_analytics\\openweather/Tokio_2023_08_21.csv.\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary libraries (installation required)\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from pandas import json_normalize\n",
        "from datetime import datetime\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Create the list of cities and coords to use as params and to get the data.\n",
        "\n",
        "cities_list = [\"London\", \"New York\", \"Cordoba\", \"Taipei\", \"Buenos_Aires\", \"Mexico_DF\", \"Dublin\", \"Tilfis\", \"Bogota\", \"Tokio\"]\n",
        "coord_list = [\"lat=51.5074&lon=-0.1278\", \"lat=40.7128&lon=-74.0060\", \"lat=-31.4197&lon=-64.1915\", \"lat=25.0330&lon=121.5654\", \"lat=-34.6037&lon=-58.3816\", \"lat=19.4326&lon=-99.1332\", \"lat=53.3498&lon=-6.2603\", \"lat=38.7223&lon=21.7632\", \"lat=4.7110&lon=-74.0721\", \"lat=35.6895&lon=139.6917\"]\n",
        "\n",
        "# Get the API KEY from OpenWeatherMap site (registration needed).\n",
        "\n",
        "api_key = \"5c9baa308e145fda6b5029762b514301\"\n",
        "\n",
        "# Create a folder to store the CSV files.\n",
        "folder_path = \"data_analytics\\openweather\"\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "# Loop through each city and coords.\n",
        "# Build the API URL and send a GET request to the API. The response is stored in a variable.\n",
        "# Check the response status code.\n",
        "\n",
        "for city, coords in zip(cities_list, coord_list):\n",
        "    url = f'https://api.openweathermap.org/data/2.5/weather?{coords}&appid={api_key}&units=metric'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        response_json = response.json()\n",
        "\n",
        "# Extract the JSON data from the response and flatten the nested \"weather\" data in the JSON response.\n",
        "# Concatenate he flattened \"weather\" data with the rest of the JSON data to create a DataFrame for the current city.\n",
        "# The weatehr columns is dropped since its data has been already extracted.\n",
        "\n",
        "        normalized_weather = json_normalize(response_json['weather'])\n",
        "        city_df = pd.concat([json_normalize(response_json), normalized_weather], axis=1).drop(columns='weather')\n",
        "\n",
        "# Generate filename and filepath.\n",
        "\n",
        "        current_date = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
        "        filename = f\"{city}_{current_date}.csv\"\n",
        "        filepath = os.path.join(folder_path, filename)\n",
        "\n",
        "# Save the city-specific DataFrame to a CSV file.\n",
        "# Print success or error message.\n",
        "\n",
        "        city_df.to_csv(filepath, index=False)\n",
        "        print(f\"The CSV file for {city} has been saved into {filepath}.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Error for {city}. Status Code:\", response.status_code)"
      ]
    }
  ]
}